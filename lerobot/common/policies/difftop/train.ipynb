{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_zs (next state) shape: torch.Size([64, 114])\n",
      "Reconstructed action shape: torch.Size([64, 2])\n",
      "z_mu shape: torch.Size([64, 64])\n",
      "z_logvar shape: torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from cvae_utilities import *\n",
    "\n",
    "# # Define dimensions for testing\n",
    "# state_dim = 96*96  # Dimensionality of the state input\n",
    "# action_dim = 2  # Dimensionality of the action input\n",
    "# latent_dim_state = 50  # Dimensionality of the latent space for states\n",
    "# latent_dim_action = 2  # Dimensionality of the latent space for actions (identity here)\n",
    "# posterior_dim = 64  # Dimensionality of the posterior latent space\n",
    "\n",
    "# # Create dummy data\n",
    "# batch_size = 64  # Number of samples in a batch\n",
    "# state = torch.randn(batch_size, state_dim)  # Random state tensor\n",
    "# action = torch.randn(batch_size, action_dim)  # Random action tensor\n",
    "\n",
    "# # Initialize the model\n",
    "# model = CVAEWithDefaultNetwork(\n",
    "#     state_dim=state_dim,\n",
    "#     action_dim=action_dim,\n",
    "#     latent_dim_state=latent_dim_state,\n",
    "#     latent_dim_action=latent_dim_action,\n",
    "#     posterior_dim=posterior_dim\n",
    "# )\n",
    "\n",
    "# # Test the forward pass\n",
    "# reconstructed_action, z_mu, z_logvar, _zs = model(state, action)\n",
    "\n",
    "# # Print the outputs\n",
    "# # print(\"Reward shape:\", reward.shape)\n",
    "# # print(\"Reward values:\", reward)\n",
    "# print(\"_zs (next state) shape:\", _zs.shape)\n",
    "# # print(\"_zs values:\", _zs)\n",
    "# # print(\"Fused latent shape:\", fused_latent.shape)\n",
    "# # print(\"Fused latent values:\", fused_latent)\n",
    "# # print(\"Reconstructed state shape:\", reconstructed_state.shape)\n",
    "# # print(\"Reconstructed state values:\", reconstructed_state)\n",
    "# print(\"Reconstructed action shape:\", reconstructed_action.shape)\n",
    "# # print(\"Reconstructed action values:\", reconstructed_action)\n",
    "# print(\"z_mu shape:\", z_mu.shape)\n",
    "# # print(\"z_mu values:\", z_mu)\n",
    "# print(\"z_logvar shape:\", z_logvar.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    'resnet18.a1_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # Ensure input is 96x96\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 512, 7, 7) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 212 files: 100%|██████████| 212/212 [00:00<00:00, 12114.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "# Set up the dataset.\n",
    "delta_timestamps = {\n",
    "    # Load the previous image and state at -0.1 seconds before current frame,\n",
    "    # then load current image and state corresponding to 0.0 second.\n",
    "    \"observation.image\": [0.0],\n",
    "    \"observation.state\": [0.0],\n",
    "    # Load the previous action (-0.1), the next action to be executed (0.0),\n",
    "    # and 14 future actions with a 0.1 seconds spacing. All these actions will be\n",
    "    # used to supervise the policy.\n",
    "    \"action\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3],\n",
    "}\n",
    "\n",
    "dataset = LeRobotDataset(\"lerobot/pusht\", delta_timestamps=delta_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for offline training.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    # pin_memory=device != torch.device(\"cpu\"),\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,7).repeat(2).reshape(6,2).reshape(1,-1)[0,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'observation.image_is_pad', 'observation.state_is_pad', 'action_is_pad'])\n",
      "torch.Size([64, 1, 3, 96, 96])\n",
      "torch.Size([64, 1, 2])\n",
      "torch.Size([64, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    # batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "    print(batch.keys())\n",
    "    print(batch[\"observation.image\"].shape)\n",
    "    print(batch[\"observation.state\"].shape)\n",
    "    print(batch[\"action\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example.py\n",
    "import gymnasium as gym\n",
    "import gym_pusht\n",
    "\n",
    "env = gym.make(\"gym_pusht/PushT-v0\", obs_type=\"pixels\", render_mode=\"rgb_array\")\n",
    "observation, info = env.reset()\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # Ensure input is 96x96\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    print(observation.shape)\n",
    "    image = env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import theseus as th\n",
    "import copy\n",
    "from cvae_utilities import *\n",
    "\n",
    "class CVAEWithTrajectoryOptimization(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CVAEWithTrajectoryOptimization, self).__init__()\n",
    "        state_dim = cfg.state_dim\n",
    "        action_dim = cfg.action_dim * cfg.horizon\n",
    "        latent_dim_state = cfg.latent_dim_state \n",
    "        latent_dim_action = cfg.latent_dim_action * cfg.horizon\n",
    "        posterior_dim = cfg.posterior_dim\n",
    "        device = cfg.device\n",
    "        self.state_encoder = StateEncoder(state_dim, latent_dim_state).to(device)\n",
    "        self.action_encoder = ActionEncoder(action_dim, latent_dim_action).to(device)\n",
    "        self.fusing_encoder = FusingEncoder(latent_dim_state, latent_dim_action, posterior_dim).to(device)\n",
    "        self.dynamics_function = DynamicsFunction(latent_dim_state, latent_dim_action, posterior_dim).to(device)\n",
    "        self.action_decoder = ActionDecoder(posterior_dim, latent_dim_state, action_dim).to(device)\n",
    "        self.reward_decoder = RewardDecoder(latent_dim_state, latent_dim_action, posterior_dim).to(device)\n",
    "        self.posterior_dim = posterior_dim\n",
    "        self.device = device\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, zs, za):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the model.\n",
    "        Args:\n",
    "            obs: Observation (raw img input), shape [batch_size, state_dim].\n",
    "            state: State (latent state input), shape [batch_size, state_dim].\n",
    "            action: Action (latent action input), shape [batch_size, horizon * action_dim].\n",
    "        Returns:\n",
    "            reconstructed_action: Reconstructed action, shape [batch_size, horizon, action_dim].\n",
    "            z_mu: Mean of the posterior Gaussian, shape [batch_size, posterior_dim].\n",
    "            z_logvar: Log-variance of the posterior Gaussian, shape [batch_size, posterior_dim].\n",
    "            _zs: Predicted next latent state, shape [batch_size, state_dim].\n",
    "        \"\"\"\n",
    "    \n",
    "        # Encode state and action\n",
    "        # zs = self.state_encoder(obs, state)\n",
    "        # za = self.action_encoder(action)\n",
    "\n",
    "        # Fuse state and action for posterior Gaussian\n",
    "        z_mu, z_logvar = self.fusing_encoder(zs, za)\n",
    "\n",
    "        # Sample from posterior Gaussian\n",
    "        fused_latent = self.reparameterize(z_mu, z_logvar)\n",
    "\n",
    "        reconstructed_action = self.action_decoder(fused_latent, zs)\n",
    "\n",
    "        # Predict next latent state\n",
    "        _zs = self.dynamics_function(zs, self.action_encoder(reconstructed_action), fused_latent)#TODO: check if this is correct\n",
    "\n",
    "        return reconstructed_action, z_mu, z_logvar, _zs\n",
    "    \n",
    "    def generate_action(self, obs, state, z):\n",
    "        \"\"\"\n",
    "        Generate an action based on the given observation.\n",
    "        Args:\n",
    "            obs: Observation (raw state input), shape [batch_size, state_dim].\n",
    "            state: State (latent state input), shape [batch_size, state_dim].\n",
    "            z: Latent variable z, shape [batch_size, posterior_dim].\n",
    "        Returns:\n",
    "            action: Generated action, shape [batch_size, action_dim].\n",
    "        \"\"\"\n",
    "        # Ensure observation is a PyTorch tensor\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float32, device=self.device)\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
    "\n",
    "\n",
    "        if obs.ndim == 1:\n",
    "            obs = obs.unsqueeze(0)  # Add batch dimension if necessary\n",
    "        if state.ndim == 1:\n",
    "            state = state.unsqueeze(0)  # Add batch dimension if necessary\n",
    "\n",
    "        # Encode observation into latent state\n",
    "        zs = self.state_encoder(obs, state)  # Encoded latent state\n",
    "\n",
    "        # # Sample latent variable z (assuming zero-mean Gaussian prior)\n",
    "        # z = torch.randn(obs.shape[0], self.posterior_dim, device=self.device)  # Prior sample for z\n",
    "\n",
    "        # Decode action from latent state and z\n",
    "        action = self.action_decoder(z, zs)  # Reconstruct action\n",
    "\n",
    "        return action\n",
    "\n",
    "    def plan_with_theseus_update(self, obs, state, action, horizon, gamma, model, cfg, eval_mode=False):\n",
    "        \"\"\"\n",
    "        Perform trajectory optimization using Theseus.\n",
    "        Args:\n",
    "            obs: Observation (raw state input).\n",
    "            horizon: Planning horizon.\n",
    "            gamma: Discount factor.\n",
    "            model: The CVAE model containing dynamics and state encoders.\n",
    "            cfg: Configuration object (for damping, step size, etc.).\n",
    "            eval_mode: Whether to evaluate without gradients.\n",
    "        \"\"\"\n",
    "        # Prepare initial observation\n",
    "        batch_size = obs.shape[0]\n",
    "        obs = torch.tensor(obs[:,0,...], dtype=torch.float32, device=self.device)#.unsqueeze(0)  # [1, obs_dim]\n",
    "        state = torch.tensor(state[:,0,...], dtype=torch.float32, device=self.device)#.unsqueeze(0)  # [1, state_dim]\n",
    "        horizon = int(min(horizon, cfg.horizon))  # Clip planning horizon\n",
    "\n",
    "        # Initialize latent state and actions\n",
    "          # Latent state\n",
    "        # actions = torch.zeros(batch_size, horizon, cfg.action_dim, device=self.device, requires_grad=True)  # Initial actions\n",
    "\n",
    "        # Precompute initial actions using policy (if available)\n",
    "        pi_actions = torch.empty(batch_size, horizon, cfg.action_dim * horizon, device=self.device)\n",
    "        zs = model.state_encoder(obs, state)\n",
    "        zs0 = zs.clone()\n",
    "        # pz = torch.randn(batch_size, model.posterior_dim, device=self.device)\n",
    "        # pz0 = pz.clone()\n",
    "        # with torch.no_grad():\n",
    "        # consistance_loss = 0 #TODO: calculate consistance loss by mse(_zs) KL(zp|N(0,1))\n",
    "        for t in range(horizon):\n",
    "            # pi_actions[:,t] = model.generate_action(obs, state, pz)\n",
    "            za = model.action_encoder(action[:,2*t:2*(horizon+t)])\n",
    "            reconstructed_action, z_mu, z_logvar, (zs0, zp) = model(zs0, za)\n",
    "            pi_actions[:,t] = reconstructed_action\n",
    "        init_actions = pi_actions.view(batch_size, -1)  # Initial actions for Theseus\n",
    "\n",
    "        # Define cost function\n",
    "        def value_cost_fn(optim_vars, aux_vars):\n",
    "            actions = optim_vars[0].tensor  # [1, horizon * action_dim]\n",
    "            print(actions.shape)\n",
    "            actions = actions.view(1, horizon, cfg.action_dim * horizon)\n",
    "            obs = aux_vars[0].tensor\n",
    "            state = aux_vars[1].tensor\n",
    "            # pz = aux_vars[2].tensor\n",
    "            z = model.state_encoder(obs, state)  # Latent state\n",
    "            total_reward = 0.0\n",
    "            discount = 1.0\n",
    "            pz = torch.randn(batch_size, model.posterior_dim, device=self.device)\n",
    "            # Compute cumulative reward\n",
    "            for t in range(horizon):\n",
    "                reward = model.reward_decoder(z, actions[:,t], pz)\n",
    "                z, pz = model.dynamics_function(z, actions[:,t], pz)\n",
    "                total_reward += discount * reward\n",
    "                discount *= gamma\n",
    "            err = -total_reward.nan_to_num_(0) + 1e3\n",
    "            return err\n",
    "\n",
    "        # Set up Theseus optimization\n",
    "        # actions_vars = []\n",
    "        # obs_vars = []\n",
    "        # state_vars = []\n",
    "        # for i in range(batch_size):\n",
    "        #     actions_vars.append(th.Variable(init_actions[i], name=\"actions\"))\n",
    "        #     obs_vars.append(th.Variable(obs[i], name=\"obs\"))\n",
    "        #     state_vars.append(th.Variable(state[i], name=\"state\"))\n",
    "        objective = th.Objective()\n",
    "        theseus_inputs = {}\n",
    "        for i in range(batch_size):\n",
    "            actions_var = th.Variable(init_actions[i], name=f\"actions_{i}\")\n",
    "            obs_var = th.Variable(obs[i], name=f\"obs_{i}\")\n",
    "            state_var = th.Variable(state[i], name=f\"state_{i}\")\n",
    "            cost_function = th.AutoDiffCostFunction(\n",
    "                [actions_var],\n",
    "                value_cost_fn,\n",
    "                dim=0,\n",
    "                aux_vars=[obs_var, state_var],#, posterior],\n",
    "                name=f\"value_cost_fn{i}\",\n",
    "            )\n",
    "            objective.add(cost_function)\n",
    "            theseus_inputs.update({\n",
    "                f\"actions_{i}\": init_actions[i],\n",
    "                f\"obs_{i}\": obs[i],\n",
    "                f\"state_{i}\": state[i]\n",
    "            })\n",
    "        # print(theseus_inputs)\n",
    "        # posterior = th.Variable(pz0, name=\"posterior\")\n",
    "\n",
    "        # cost_function = th.AutoDiffCostFunction(\n",
    "        #     [actions_var],\n",
    "        #     value_cost_fn,\n",
    "        #     dim=1,\n",
    "        #     aux_vars=[obs_var, state_var],#, posterior],\n",
    "        #     name=\"value_cost_fn\",\n",
    "        # )\n",
    "        \n",
    "        # objective.add(cost_function)\n",
    "        optimizer = th.LevenbergMarquardt(\n",
    "            objective,\n",
    "            th.CholeskyDenseSolver,\n",
    "            max_iterations=cfg.max_iterations,\n",
    "            step_size=cfg.step_size,\n",
    "        )\n",
    "        theseus_layer = th.TheseusLayer(optimizer)\n",
    "        theseus_layer.to(device=self.device)\n",
    "\n",
    "        # theseus_inputs = {\"actions\": init_actions, \"obs\": obs, \"state\": state}#, \"posterior\": pz0}\n",
    "\n",
    "        # Solve optimization problem\n",
    "        updated_inputs, info = theseus_layer.forward(\n",
    "            theseus_inputs,\n",
    "            optimizer_kwargs={\n",
    "                \"track_best_solution\": True,\n",
    "                \"damping\": cfg.damping,\n",
    "                \"verbose\": True,\n",
    "            },\n",
    "        )\n",
    "        best_actions = info.best_solution[\"actions\"].view(horizon, -1)\n",
    "\n",
    "        return best_actions\n",
    "\n",
    "# Example Configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.horizon = 7\n",
    "        self.action_dim = 2\n",
    "        # Theseus optimization parameters\n",
    "        self.max_iterations = 100\n",
    "        self.step_size = 1e-2\n",
    "        self.damping = 1e-3\n",
    "        self.min_std = 1e-4\n",
    "        self.discount = 0.99\n",
    "        self.state_dim = 512*3*3 + 2\n",
    "\n",
    "        self.latent_dim_state = 50\n",
    "        self.latent_dim_action = self.action_dim\n",
    "        self.posterior_dim = 64\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139914/2686813838.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs = torch.tensor(obs[:,0,...], dtype=torch.float32, device=self.device)#.unsqueeze(0)  # [1, obs_dim]\n",
      "/tmp/ipykernel_139914/2686813838.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state[:,0,...], dtype=torch.float32, device=self.device)#.unsqueeze(0)  # [1, state_dim]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'dof'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# obs = (obs, state)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Perform trajectory optimization with Theseus\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m optimized_actions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan_with_theseus_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Actions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimized_actions)\n",
      "Cell \u001b[0;32mIn[166], line 192\u001b[0m, in \u001b[0;36mCVAEWithTrajectoryOptimization.plan_with_theseus_update\u001b[0;34m(self, obs, state, action, horizon, gamma, model, cfg, eval_mode)\u001b[0m\n\u001b[1;32m    175\u001b[0m     theseus_inputs\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: init_actions[i],\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: obs[i],\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: state[i]\n\u001b[1;32m    179\u001b[0m     })\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# print(theseus_inputs)\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# posterior = th.Variable(pz0, name=\"posterior\")\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# objective.add(cost_function)\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLevenbergMarquardt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCholeskyDenseSolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m theseus_layer \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mTheseusLayer(optimizer)\n\u001b[1;32m    199\u001b[0m theseus_layer\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/nonlinear/levenberg_marquardt.py:69\u001b[0m, in \u001b[0;36mLevenbergMarquardt.__init__\u001b[0;34m(self, objective, linear_solver_cls, vectorize, linearization_cls, linearization_kwargs, linear_solver_kwargs, abs_err_tolerance, rel_err_tolerance, max_iterations, step_size, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     57\u001b[0m     objective: Objective,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     68\u001b[0m ):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_solver_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_solver_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinearization_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinearization_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinearization_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinearization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_solver_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_solver_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_err_tolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabs_err_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_err_tolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_err_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_ellipsoidal \u001b[38;5;241m=\u001b[39m _check_linear_solver(\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_solver, _LM_ALLOWED_ELLIPS_DAMP_SOLVERS\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_adaptive \u001b[38;5;241m=\u001b[39m _check_linear_solver(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_solver, _LM_ALLOWED_ADAPTIVE_DAMP_SOLVERS\n\u001b[1;32m     87\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/nonlinear/nonlinear_least_squares.py:90\u001b[0m, in \u001b[0;36mNonlinearLeastSquares.__init__\u001b[0;34m(self, objective, linear_solver_cls, vectorize, linearization_cls, linearization_kwargs, linear_solver_kwargs, abs_err_tolerance, rel_err_tolerance, max_iterations, step_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m linear_solver_cls \u001b[38;5;241m=\u001b[39m linear_solver_cls \u001b[38;5;129;01mor\u001b[39;00m CholeskyDenseSolver\n\u001b[1;32m     89\u001b[0m linear_solver_kwargs \u001b[38;5;241m=\u001b[39m linear_solver_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_solver \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_solver_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinearization_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinearization_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinearization_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinearization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlinear_solver_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordering \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_solver\u001b[38;5;241m.\u001b[39mlinearization\u001b[38;5;241m.\u001b[39mordering\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmp_optim_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(v\u001b[38;5;241m.\u001b[39mcopy(new_name\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordering)\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/linear/dense_solver.py:152\u001b[0m, in \u001b[0;36mCholeskyDenseSolver.__init__\u001b[0;34m(self, objective, linearization_cls, linearization_kwargs, check_singular)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    147\u001b[0m     objective: Objective,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     check_singular: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m ):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinearization_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinearization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/linear/dense_solver.py:33\u001b[0m, in \u001b[0;36mDenseSolver.__init__\u001b[0;34m(self, objective, linearization_cls, linearization_kwargs, check_singular)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m linearization_cls \u001b[38;5;241m!=\u001b[39m DenseLinearization:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDenseSolver only works with theseus.nonlinear.DenseLinearization, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlinearization_cls\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinearization_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinearization_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearization: DenseLinearization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearization\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_singular \u001b[38;5;241m=\u001b[39m check_singular\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/linear/linear_solver.py:25\u001b[0m, in \u001b[0;36mLinearSolver.__init__\u001b[0;34m(self, objective, linearization_cls, linearization_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m     objective: Objective,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     23\u001b[0m ):\n\u001b[1;32m     24\u001b[0m     linearization_kwargs \u001b[38;5;241m=\u001b[39m linearization_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearization: Linearization \u001b[38;5;241m=\u001b[39m \u001b[43mlinearization_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlinearization_kwargs\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/dense_linearization.py:23\u001b[0m, in \u001b[0;36mDenseLinearization.__init__\u001b[0;34m(self, objective, ordering, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m     objective: Objective,\n\u001b[1;32m     20\u001b[0m     ordering: Optional[VariableOrdering] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     22\u001b[0m ):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/theseus/optimizer/linearization.py:35\u001b[0m, in \u001b[0;36mLinearization.__init__\u001b[0;34m(self, objective, ordering, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m col_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m ordering:\n\u001b[0;32m---> 35\u001b[0m     v_dim \u001b[38;5;241m=\u001b[39m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdof\u001b[49m()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_start_cols\u001b[38;5;241m.\u001b[39mappend(col_counter)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_dims\u001b[38;5;241m.\u001b[39mappend(v_dim)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'dof'"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Config and hyperparameters\n",
    "    cfg = Config()\n",
    "    \n",
    "\n",
    "    # Create CVAE model\n",
    "    model = CVAEWithTrajectoryOptimization(cfg)\n",
    "\n",
    "    # Example observation\n",
    "    obs = torch.randn(64,1,3,96,96).to(device)\n",
    "    state = torch.randn(64,1,2).to(device)\n",
    "    action = torch.randn(64,28).to(device)\n",
    "    # obs = (obs, state)\n",
    "\n",
    "    # Perform trajectory optimization with Theseus\n",
    "    optimized_actions = model.plan_with_theseus_update(obs, state, action, horizon=cfg.horizon, gamma=cfg.discount, model=model, cfg=cfg)\n",
    "    print(\"Optimized Actions:\", optimized_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
