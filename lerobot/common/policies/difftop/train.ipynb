{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_zs (next state) shape: torch.Size([64, 114])\n",
      "Reconstructed action shape: torch.Size([64, 2])\n",
      "z_mu shape: torch.Size([64, 64])\n",
      "z_logvar shape: torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from cvae_utilities import *\n",
    "\n",
    "# # Define dimensions for testing\n",
    "# state_dim = 96*96  # Dimensionality of the state input\n",
    "# action_dim = 2  # Dimensionality of the action input\n",
    "# latent_dim_state = 50  # Dimensionality of the latent space for states\n",
    "# latent_dim_action = 2  # Dimensionality of the latent space for actions (identity here)\n",
    "# posterior_dim = 64  # Dimensionality of the posterior latent space\n",
    "\n",
    "# # Create dummy data\n",
    "# batch_size = 64  # Number of samples in a batch\n",
    "# state = torch.randn(batch_size, state_dim)  # Random state tensor\n",
    "# action = torch.randn(batch_size, action_dim)  # Random action tensor\n",
    "\n",
    "# # Initialize the model\n",
    "# model = CVAEWithDefaultNetwork(\n",
    "#     state_dim=state_dim,\n",
    "#     action_dim=action_dim,\n",
    "#     latent_dim_state=latent_dim_state,\n",
    "#     latent_dim_action=latent_dim_action,\n",
    "#     posterior_dim=posterior_dim\n",
    "# )\n",
    "\n",
    "# # Test the forward pass\n",
    "# reconstructed_action, z_mu, z_logvar, _zs = model(state, action)\n",
    "\n",
    "# # Print the outputs\n",
    "# # print(\"Reward shape:\", reward.shape)\n",
    "# # print(\"Reward values:\", reward)\n",
    "# print(\"_zs (next state) shape:\", _zs.shape)\n",
    "# # print(\"_zs values:\", _zs)\n",
    "# # print(\"Fused latent shape:\", fused_latent.shape)\n",
    "# # print(\"Fused latent values:\", fused_latent)\n",
    "# # print(\"Reconstructed state shape:\", reconstructed_state.shape)\n",
    "# # print(\"Reconstructed state values:\", reconstructed_state)\n",
    "# print(\"Reconstructed action shape:\", reconstructed_action.shape)\n",
    "# # print(\"Reconstructed action values:\", reconstructed_action)\n",
    "# print(\"z_mu shape:\", z_mu.shape)\n",
    "# # print(\"z_mu values:\", z_mu)\n",
    "# print(\"z_logvar shape:\", z_logvar.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    'resnet18.a1_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # Ensure input is 96x96\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 512, 7, 7) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 212 files: 100%|██████████| 212/212 [00:00<00:00, 12114.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "# Set up the dataset.\n",
    "delta_timestamps = {\n",
    "    # Load the previous image and state at -0.1 seconds before current frame,\n",
    "    # then load current image and state corresponding to 0.0 second.\n",
    "    \"observation.image\": [0.0],\n",
    "    \"observation.state\": [0.0],\n",
    "    # Load the previous action (-0.1), the next action to be executed (0.0),\n",
    "    # and 14 future actions with a 0.1 seconds spacing. All these actions will be\n",
    "    # used to supervise the policy.\n",
    "    \"action\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3],\n",
    "}\n",
    "\n",
    "dataset = LeRobotDataset(\"lerobot/pusht\", delta_timestamps=delta_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for offline training.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    # pin_memory=device != torch.device(\"cpu\"),\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,7).repeat(2).reshape(6,2).reshape(1,-1)[0,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'observation.image_is_pad', 'observation.state_is_pad', 'action_is_pad'])\n",
      "torch.Size([64, 1, 3, 96, 96])\n",
      "torch.Size([64, 1, 2])\n",
      "torch.Size([64, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    # batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "    print(batch.keys())\n",
    "    print(batch[\"observation.image\"].shape)\n",
    "    print(batch[\"observation.state\"].shape)\n",
    "    print(batch[\"action\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example.py\n",
    "import gymnasium as gym\n",
    "import gym_pusht\n",
    "\n",
    "env = gym.make(\"gym_pusht/PushT-v0\", obs_type=\"pixels\", render_mode=\"rgb_array\")\n",
    "observation, info = env.reset()\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # Ensure input is 96x96\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    print(observation.shape)\n",
    "    image = env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import theseus as th\n",
    "import copy\n",
    "from cvae_utilities import *\n",
    "import copy\n",
    "\n",
    "class CVAEWithTrajectoryOptimization(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CVAEWithTrajectoryOptimization, self).__init__()\n",
    "        state_dim = cfg.state_dim\n",
    "        action_dim = cfg.action_dim * cfg.horizon\n",
    "        latent_dim_state = cfg.latent_dim_state \n",
    "        latent_dim_action = cfg.latent_dim_action * cfg.horizon\n",
    "        posterior_dim = cfg.posterior_dim\n",
    "        device = cfg.device\n",
    "        self.state_encoder = StateEncoder(state_dim, latent_dim_state).to(device)\n",
    "        self.action_encoder = ActionEncoder(action_dim, latent_dim_action).to(device)\n",
    "        self.fusing_encoder = FusingEncoder(latent_dim_state, latent_dim_action, posterior_dim).to(device)\n",
    "        self.dynamics_function = DynamicsFunction(latent_dim_state, latent_dim_action, posterior_dim).to(device)\n",
    "        self.action_decoder = ActionDecoder(posterior_dim, latent_dim_state, action_dim).to(device)\n",
    "        self.reward_decoder = RewardDecoder(latent_dim_state, latent_dim_action, posterior_dim).to(device)\n",
    "        self.posterior_dim = posterior_dim\n",
    "        self.device = device\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, zs, za):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the model.\n",
    "        Args:\n",
    "            obs: Observation (raw img input), shape [batch_size, state_dim].\n",
    "            state: State (latent state input), shape [batch_size, state_dim].\n",
    "            action: Action (latent action input), shape [batch_size, horizon * action_dim].\n",
    "        Returns:\n",
    "            reconstructed_action: Reconstructed action, shape [batch_size, horizon, action_dim].\n",
    "            z_mu: Mean of the posterior Gaussian, shape [batch_size, posterior_dim].\n",
    "            z_logvar: Log-variance of the posterior Gaussian, shape [batch_size, posterior_dim].\n",
    "            _zs: Predicted next latent state, shape [batch_size, state_dim].\n",
    "        \"\"\"\n",
    "    \n",
    "        # Encode state and action\n",
    "        # zs = self.state_encoder(obs, state)\n",
    "        # za = self.action_encoder(action)\n",
    "\n",
    "        # Fuse state and action for posterior Gaussian\n",
    "        z_mu, z_logvar = self.fusing_encoder(zs, za)\n",
    "\n",
    "        # Sample from posterior Gaussian\n",
    "        fused_latent = self.reparameterize(z_mu, z_logvar)\n",
    "\n",
    "        reconstructed_action = self.action_decoder(fused_latent, zs)\n",
    "\n",
    "        # Predict next latent state\n",
    "        _zs = self.dynamics_function(zs, self.action_encoder(reconstructed_action), fused_latent)#TODO: check if this is correct\n",
    "\n",
    "        return reconstructed_action, z_mu, z_logvar, _zs\n",
    "    \n",
    "    def generate_action(self, obs, state, z):\n",
    "        \"\"\"\n",
    "        Generate an action based on the given observation.\n",
    "        Args:\n",
    "            obs: Observation (raw state input), shape [batch_size, state_dim].\n",
    "            state: State (latent state input), shape [batch_size, state_dim].\n",
    "            z: Latent variable z, shape [batch_size, posterior_dim].\n",
    "        Returns:\n",
    "            action: Generated action, shape [batch_size, action_dim].\n",
    "        \"\"\"\n",
    "        # Ensure observation is a PyTorch tensor\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float32, device=self.device)\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
    "\n",
    "\n",
    "        if obs.ndim == 1:\n",
    "            obs = obs.unsqueeze(0)  # Add batch dimension if necessary\n",
    "        if state.ndim == 1:\n",
    "            state = state.unsqueeze(0)  # Add batch dimension if necessary\n",
    "\n",
    "        # Encode observation into latent state\n",
    "        zs = self.state_encoder(obs, state)  # Encoded latent state\n",
    "\n",
    "        # # Sample latent variable z (assuming zero-mean Gaussian prior)\n",
    "        # z = torch.randn(obs.shape[0], self.posterior_dim, device=self.device)  # Prior sample for z\n",
    "\n",
    "        # Decode action from latent state and z\n",
    "        action = self.action_decoder(z, zs)  # Reconstruct action\n",
    "\n",
    "        return action\n",
    "\n",
    "    def plan_with_theseus_update(self, obs, state, action, horizon, gamma, model, cfg, eval_mode=False):\n",
    "        \"\"\"\n",
    "        Perform trajectory optimization using Theseus.\n",
    "        Args:\n",
    "            obs: Observation (raw state input).\n",
    "            horizon: Planning horizon.\n",
    "            gamma: Discount factor.\n",
    "            model: The CVAE model containing dynamics and state encoders.\n",
    "            cfg: Configuration object (for damping, step size, etc.).\n",
    "            eval_mode: Whether to evaluate without gradients.\n",
    "        \"\"\"\n",
    "        # Prepare initial observation\n",
    "        batch_size = obs.shape[0]\n",
    "        obs = torch.tensor(obs[:,0,...], dtype=torch.float32, device=self.device) # [bs, 3, 96, 96]\n",
    "        state = torch.tensor(state[:,0,...], dtype=torch.float32, device=self.device)# [bs, 2]\n",
    "        action = torch.tensor(action, dtype=torch.float32, device=self.device) # [bs, horizon * 2 * 2]\n",
    "        horizon = int(min(horizon, cfg.horizon))  # Clip planning horizon\n",
    "\n",
    "        # Initialize latent state and actions\n",
    "          # Latent state\n",
    "        # actions = torch.zeros(batch_size, horizon, cfg.action_dim, device=self.device, requires_grad=True)  # Initial actions\n",
    "\n",
    "        # Precompute initial actions using policy (if available)\n",
    "        pi_actions = torch.empty(batch_size, horizon, cfg.action_dim * horizon, device=self.device)\n",
    "        zs = model.state_encoder(obs, state) # 【bs, 50]\n",
    "        zs0 = zs.clone()\n",
    "        # pz = torch.randn(batch_size, model.posterior_dim, device=self.device)\n",
    "        # pz0 = pz.clone()\n",
    "        # with torch.no_grad():\n",
    "        # consistance_loss = 0 #TODO: calculate consistance loss by mse(_zs) KL(zp|N(0,1))\n",
    "        for t in range(horizon):\n",
    "            # pi_actions[:,t] = model.generate_action(obs, state, pz)\n",
    "            za = model.action_encoder(action[:,2*t:2*(horizon+t)]) # [bs, 14]\n",
    "            reconstructed_action, z_mu, z_logvar, (zs0, zp) = model(zs0, za) # [bs, 14]\n",
    "            pi_actions[:,t] = reconstructed_action\n",
    "        # init_actions = pi_actions.view(1, -1)  # Initial actions for Theseus\n",
    "\n",
    "        # actions = torch.zeros(batch_size, horizon * cfg.action_dim, device=self.device, requires_grad=True)  # Initial actions\n",
    "        \n",
    "        # Define cost function\n",
    "        def value_cost_fn(optim_vars, aux_vars):\n",
    "            actions = optim_vars[0].tensor  # [bs, horizon * action_dim]\n",
    "\n",
    "            obs = aux_vars[0].tensor\n",
    "            state = aux_vars[1].tensor\n",
    "            pz = aux_vars[2].tensor\n",
    "\n",
    "            actions = actions.view(batch_size, horizon, cfg.action_dim * horizon)\n",
    "            obs = obs.squeeze(0)\n",
    "            print(obs.shape)\n",
    "            state = state.squeeze(0)\n",
    "            print(state.shape)\n",
    "            pz = pz.squeeze(0)\n",
    "\n",
    "            z = model.state_encoder(obs, state)  # Latent state\n",
    "            total_reward = 0.0\n",
    "            discount = 1.0\n",
    "            \n",
    "            # Compute cumulative reward\n",
    "            for t in range(horizon):\n",
    "                reward = model.reward_decoder(z, actions[:,t], pz)\n",
    "                z, pz = model.dynamics_function(z, actions[:,t], pz)\n",
    "                total_reward += discount * reward\n",
    "                discount *= gamma\n",
    "            err = -torch.nan_to_num(total_reward, nan=0.0) + 1e3\n",
    "            # print(err.mean(axis = 0).shape)\n",
    "            return err.view(1,-1)#.mean(axis = 0).view(1,1)\n",
    "        \n",
    "        init_actions = pi_actions.view(1, -1)  # Initial actions for Theseus\n",
    "        input_obs = obs.unsqueeze(0)\n",
    "        input_state = state.unsqueeze(0)\n",
    "        input_pz = torch.randn(1, batch_size, model.posterior_dim, device=self.device)\n",
    "\n",
    "        actions_var = th.Vector(tensor = init_actions, name=\"actions\")\n",
    "        obs_var = th.Variable(input_obs, name=\"obs\")\n",
    "        state_var = th.Variable(input_state, name=\"state\")\n",
    "        # pz = torch.randn(1, batch_size, model.posterior_dim, device=self.device)\n",
    "        posterior = th.Variable(input_pz, name=\"posterior\")\n",
    "\n",
    "        cost_function = th.AutoDiffCostFunction(\n",
    "            [actions_var],\n",
    "            value_cost_fn,\n",
    "            dim=64,\n",
    "            aux_vars=[obs_var, state_var, posterior],\n",
    "            name=\"value_cost_fn\",\n",
    "        )\n",
    "\n",
    "        objective = th.Objective()\n",
    "        objective.add(cost_function)\n",
    "        optimizer = th.LevenbergMarquardt(\n",
    "            objective,\n",
    "            th.CholeskyDenseSolver,\n",
    "            max_iterations=cfg.max_iterations,\n",
    "            step_size=cfg.step_size,\n",
    "        )\n",
    "        theseus_layer = th.TheseusLayer(optimizer)\n",
    "        theseus_layer.to(device=self.device)\n",
    "\n",
    "        # print(init_actions.shape)\n",
    "        \n",
    "        theseus_inputs = {\"actions\": init_actions, \"obs\": input_obs, \"state\": input_state, \"posterior\": input_pz}\n",
    "        \n",
    "        # Solve optimization problem\n",
    "        updated_inputs, info = theseus_layer.forward(\n",
    "            theseus_inputs,\n",
    "            optimizer_kwargs={\n",
    "                \"track_best_solution\": True,\n",
    "                \"damping\": cfg.damping,\n",
    "                \"verbose\": True,\n",
    "            },\n",
    "        )\n",
    "        best_actions = info.best_solution[\"actions\"].view(horizon, -1)\n",
    "\n",
    "        return best_actions\n",
    "\n",
    "# Example Configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.horizon = 7\n",
    "        self.action_dim = 2\n",
    "        # Theseus optimization parameters\n",
    "        self.max_iterations = 100\n",
    "        self.step_size = 1e-2\n",
    "        self.damping = 1e-3\n",
    "        self.min_std = 1e-4\n",
    "        self.discount = 0.99\n",
    "        self.state_dim = 512*3*3 + 2\n",
    "\n",
    "        self.latent_dim_state = 50\n",
    "        self.latent_dim_action = self.action_dim\n",
    "        self.posterior_dim = 64\n",
    "        self.device = torch.device(\"mps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 3, 96, 96])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/fkzkr3wj75j87bvhfhj_2p8c0000gp/T/ipykernel_67820/1352833770.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs = torch.tensor(obs[:,0,...], dtype=torch.float32, device=self.device) # [bs, 3, 96, 96]\n",
      "/var/folders/qj/fkzkr3wj75j87bvhfhj_2p8c0000gp/T/ipykernel_67820/1352833770.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state[:,0,...], dtype=torch.float32, device=self.device)# [bs, 2]\n",
      "/var/folders/qj/fkzkr3wj75j87bvhfhj_2p8c0000gp/T/ipykernel_67820/1352833770.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  action = torch.tensor(action, dtype=torch.float32, device=self.device) # [bs, horizon * 2 * 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 96, 96])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([64, 3, 96, 96])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([64, 3, 96, 96])\n",
      "torch.Size([64, 2])\n",
      "Nonlinear optimizer. Iteration: 0. Error: 31971798.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error while running the linear optimizer. Original error message: The operator 'aten::linalg_cholesky_ex.L' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.. Backward pass will not work. To obtain the best solution seen before the error, run with torch.no_grad()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/nonlinear/nonlinear_least_squares.py:137\u001b[0m, in \u001b[0;36mNonlinearLeastSquares._optimize_loop\u001b[0;34m(self, num_iter, info, verbose, end_iter_callback, _last_implicit_diff_step, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m         delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_delta(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m run_err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/nonlinear/levenberg_marquardt.py:133\u001b[0m, in \u001b[0;36mLevenbergMarquardt.compute_delta\u001b[0;34m(self, ellipsoidal_damping, damping_eps, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m damping_eps \u001b[38;5;241m=\u001b[39m damping_eps \u001b[38;5;28;01mif\u001b[39;00m damping_eps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1e-8\u001b[39m\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_solver\u001b[38;5;241m.\u001b[39msolve(\n\u001b[1;32m    134\u001b[0m     damping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_damping,\n\u001b[1;32m    135\u001b[0m     ellipsoidal_damping\u001b[38;5;241m=\u001b[39mellipsoidal_damping,\n\u001b[1;32m    136\u001b[0m     damping_eps\u001b[38;5;241m=\u001b[39mdamping_eps,\n\u001b[1;32m    137\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/linear/dense_solver.py:116\u001b[0m, in \u001b[0;36mDenseSolver.solve\u001b[0;34m(self, damping, ellipsoidal_damping, damping_eps, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_damping_and_solve(\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearization\u001b[38;5;241m.\u001b[39mAtb,\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearization\u001b[38;5;241m.\u001b[39mAtA,\n\u001b[1;32m    119\u001b[0m         damping\u001b[38;5;241m=\u001b[39mdamping,\n\u001b[1;32m    120\u001b[0m         ellipsoidal_damping\u001b[38;5;241m=\u001b[39mellipsoidal_damping,\n\u001b[1;32m    121\u001b[0m         damping_eps\u001b[38;5;241m=\u001b[39mdamping_eps,\n\u001b[1;32m    122\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/linear/dense_solver.py:78\u001b[0m, in \u001b[0;36mDenseSolver._apply_damping_and_solve\u001b[0;34m(self, Atb, AtA, damping, ellipsoidal_damping, damping_eps)\u001b[0m\n\u001b[1;32m     75\u001b[0m     AtA \u001b[38;5;241m=\u001b[39m DenseSolver\u001b[38;5;241m.\u001b[39m_apply_damping(\n\u001b[1;32m     76\u001b[0m         AtA, damping, ellipsoidal\u001b[38;5;241m=\u001b[39mellipsoidal_damping, eps\u001b[38;5;241m=\u001b[39mdamping_eps\n\u001b[1;32m     77\u001b[0m     )\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_sytem(Atb, AtA)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/linear/dense_solver.py:160\u001b[0m, in \u001b[0;36mCholeskyDenseSolver._solve_sytem\u001b[0;34m(self, Atb, AtA)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_solve_sytem\u001b[39m(\u001b[38;5;28mself\u001b[39m, Atb: torch\u001b[38;5;241m.\u001b[39mTensor, AtA: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 160\u001b[0m     lower \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(AtA)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcholesky_solve(Atb, lower)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::linalg_cholesky_ex.L' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# obs = (obs, state)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Perform trajectory optimization with Theseus\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m optimized_actions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mplan_with_theseus_update(obs, state, action, horizon\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mhorizon, gamma\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdiscount, model\u001b[38;5;241m=\u001b[39mmodel, cfg\u001b[38;5;241m=\u001b[39mcfg)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Actions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimized_actions)\n",
      "Cell \u001b[0;32mIn[29], line 200\u001b[0m, in \u001b[0;36mCVAEWithTrajectoryOptimization.plan_with_theseus_update\u001b[0;34m(self, obs, state, action, horizon, gamma, model, cfg, eval_mode)\u001b[0m\n\u001b[1;32m    197\u001b[0m theseus_inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_actions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_obs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_state, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_pz}\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Solve optimization problem\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m updated_inputs, info \u001b[38;5;241m=\u001b[39m theseus_layer\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    201\u001b[0m     theseus_inputs,\n\u001b[1;32m    202\u001b[0m     optimizer_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack_best_solution\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdamping\u001b[39m\u001b[38;5;124m\"\u001b[39m: cfg\u001b[38;5;241m.\u001b[39mdamping,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m     },\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    208\u001b[0m best_actions \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mbest_solution[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mview(horizon, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_actions\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/theseus_layer.py:93\u001b[0m, in \u001b[0;36mTheseusLayer.forward\u001b[0;34m(self, input_tensors, optimizer_kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mvars\u001b[39m, info \u001b[38;5;241m=\u001b[39m TheseusLayerDLMForward\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective,\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;241m*\u001b[39mdifferentiable_tensors,\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28mvars\u001b[39m, info \u001b[38;5;241m=\u001b[39m _forward(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, optimizer_kwargs, input_tensors\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39moptim_vars\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;28mvars\u001b[39m))\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values, info\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/theseus_layer.py:172\u001b[0m, in \u001b[0;36m_forward\u001b[0;34m(objective, optimizer, optimizer_kwargs, input_tensors)\u001b[0m\n\u001b[1;32m    170\u001b[0m objective\u001b[38;5;241m.\u001b[39mupdate(input_tensors)\n\u001b[1;32m    171\u001b[0m optimizer_kwargs[__FROM_THESEUS_LAYER_TOKEN__] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m info \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimizer_kwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m [var\u001b[38;5;241m.\u001b[39mtensor \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m objective\u001b[38;5;241m.\u001b[39moptim_vars\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, info\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/optimizer.py:51\u001b[0m, in \u001b[0;36mOptimizer.optimize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objectives_version \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mcurrent_version:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe objective was modified after optimizer construction, which is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrently not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_impl(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/nonlinear/nonlinear_least_squares.py:251\u001b[0m, in \u001b[0;36mNonlinearLeastSquares._optimize_impl\u001b[0;34m(self, track_best_solution, track_err_history, track_state_history, verbose, backward_mode, end_iter_callback, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m backward_num_iters, no_grad_num_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_backward_iters(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_plus_bwd_mode\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backward_mode \u001b[38;5;129;01min\u001b[39;00m [BackwardMode\u001b[38;5;241m.\u001b[39mUNROLL, BackwardMode\u001b[38;5;241m.\u001b[39mDLM]:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_loop(\n\u001b[1;32m    252\u001b[0m         start_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    253\u001b[0m         num_iter\u001b[38;5;241m=\u001b[39mbackward_num_iters,\n\u001b[1;32m    254\u001b[0m         info\u001b[38;5;241m=\u001b[39minfo,\n\u001b[1;32m    255\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    256\u001b[0m         end_iter_callback\u001b[38;5;241m=\u001b[39mend_iter_callback,\n\u001b[1;32m    257\u001b[0m         _last_implicit_diff_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# If didn't coverge, remove misleading converged_iter value\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     info\u001b[38;5;241m.\u001b[39mconverged_iter[\n\u001b[1;32m    262\u001b[0m         info\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m NonlinearOptimizerStatus\u001b[38;5;241m.\u001b[39mMAX_ITERATIONS\n\u001b[1;32m    263\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl/lib/python3.11/site-packages/theseus/optimizer/nonlinear/nonlinear_least_squares.py:144\u001b[0m, in \u001b[0;36mNonlinearLeastSquares._optimize_loop\u001b[0;34m(self, num_iter, info, verbose, end_iter_callback, _last_implicit_diff_step, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was an error while running the linear optimizer. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled():\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    145\u001b[0m         msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Backward pass will not work. To obtain \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe best solution seen before the error, run with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.no_grad()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error while running the linear optimizer. Original error message: The operator 'aten::linalg_cholesky_ex.L' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.. Backward pass will not work. To obtain the best solution seen before the error, run with torch.no_grad()"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Config and hyperparameters\n",
    "    cfg = Config()\n",
    "    device = cfg.device\n",
    "\n",
    "    # Create CVAE model\n",
    "    model = CVAEWithTrajectoryOptimization(cfg)\n",
    "\n",
    "    # Example observation\n",
    "    obs = torch.randn(64,1,3,96,96).to(device)\n",
    "    state = torch.randn(64,1,2).to(device)\n",
    "    action = torch.randn(64,28).to(device)\n",
    "    # obs = (obs, state)\n",
    "\n",
    "    # Perform trajectory optimization with Theseus\n",
    "    optimized_actions = model.plan_with_theseus_update(obs, state, action, horizon=cfg.horizon, gamma=cfg.discount, model=model, cfg=cfg)\n",
    "    print(\"Optimized Actions:\", optimized_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
