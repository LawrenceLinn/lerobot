{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lawrence/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import gym_pusht  # noqa: F401\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import numpy\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|██████████| 11/11 [00:00<00:00, 100956.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from local directory\n",
      "GPU is available. Device set to: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffusionPolicy(\n",
       "  (normalize_inputs): Normalize(\n",
       "    (buffer_observation_image): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 3x1x1 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 3x1x1 (cuda:0)]\n",
       "    )\n",
       "    (buffer_observation_state): ParameterDict(\n",
       "        (max): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "        (min): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (normalize_targets): Normalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (max): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "        (min): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (unnormalize_outputs): Unnormalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (max): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "        (min): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (diffusion): DiffusionModel(\n",
       "    (rgb_encoder): DiffusionRgbEncoder(\n",
       "      (center_crop): CenterCrop(size=[84, 84])\n",
       "      (maybe_random_crop): RandomCrop(size=(84, 84), padding=None)\n",
       "      (backbone): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pool): SpatialSoftmax(\n",
       "        (nets): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (out): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (unet): DiffusionConditionalUnet1d(\n",
       "      (diffusion_step_encoder): Sequential(\n",
       "        (0): DiffusionSinusoidalPosEmb()\n",
       "        (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (2): Mish()\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (down_modules): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(2, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=1024, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=1024, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Identity()\n",
       "          )\n",
       "          (2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=2048, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=2048, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Identity()\n",
       "          )\n",
       "          (2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 2048, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 2048, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=4096, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(2048, 2048, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 2048, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(2048, 2048, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 2048, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=4096, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(2048, 2048, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 2048, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Identity()\n",
       "          )\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (mid_modules): ModuleList(\n",
       "        (0-1): 2 x DiffusionConditionalResidualBlock1d(\n",
       "          (conv1): DiffusionConv1dBlock(\n",
       "            (block): Sequential(\n",
       "              (0): Conv1d(2048, 2048, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "              (1): GroupNorm(8, 2048, eps=1e-05, affine=True)\n",
       "              (2): Mish()\n",
       "            )\n",
       "          )\n",
       "          (cond_encoder): Sequential(\n",
       "            (0): Mish()\n",
       "            (1): Linear(in_features=260, out_features=4096, bias=True)\n",
       "          )\n",
       "          (conv2): DiffusionConv1dBlock(\n",
       "            (block): Sequential(\n",
       "              (0): Conv1d(2048, 2048, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "              (1): GroupNorm(8, 2048, eps=1e-05, affine=True)\n",
       "              (2): Mish()\n",
       "            )\n",
       "          )\n",
       "          (residual_conv): Identity()\n",
       "        )\n",
       "      )\n",
       "      (up_modules): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(4096, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=2048, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=2048, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Identity()\n",
       "          )\n",
       "          (2): ConvTranspose1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(2048, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=1024, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): DiffusionConditionalResidualBlock1d(\n",
       "            (conv1): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (cond_encoder): Sequential(\n",
       "              (0): Mish()\n",
       "              (1): Linear(in_features=260, out_features=1024, bias=True)\n",
       "            )\n",
       "            (conv2): DiffusionConv1dBlock(\n",
       "              (block): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "                (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (2): Mish()\n",
       "              )\n",
       "            )\n",
       "            (residual_conv): Identity()\n",
       "          )\n",
       "          (2): ConvTranspose1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (final_conv): Sequential(\n",
       "        (0): DiffusionConv1dBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "            (2): Mish()\n",
       "          )\n",
       "        )\n",
       "        (1): Conv1d(512, 2, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Create a directory to store the video of the evaluation\n",
    "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the diffusion policy for pusht environment\n",
    "pretrained_policy_path = Path(snapshot_download(\"lerobot/diffusion_pusht\"))\n",
    "# OR uncomment the following to evaluate a policy from the local outputs/train folder.\n",
    "# pretrained_policy_path = Path(\"outputs/train/2024-11-26/18-20-16_pusht_diffusion_default\")\n",
    "\n",
    "policy = DiffusionPolicy.from_pretrained(pretrained_policy_path)\n",
    "policy.eval()\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Device set to:\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"GPU is not available. Device set to: {device}. Inference will be slower than on GPU.\")\n",
    "    # Decrease the number of reverse-diffusion steps (trades off a bit of quality for 10x speed)\n",
    "    policy.diffusion.num_inference_steps = 10\n",
    "\n",
    "policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluation environment to render two observation types:\n",
    "# an image of the scene and state/position of the agent. The environment\n",
    "# also automatically stops running after 300 interactions/steps.\n",
    "env = gym.make(\n",
    "    \"gym_pusht/PushT-v0\",\n",
    "    obs_type=\"pixels_agent_pos\",\n",
    "    max_episode_steps=300,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.config.noise_scheduler_type = \"DDIM\"\n",
    "policy.config.n_action_steps = 1\n",
    "policy.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionConfig(n_obs_steps=2, horizon=16, n_action_steps=8, input_shapes={'observation.image': [3, 96, 96], 'observation.state': [2]}, output_shapes={'action': [2]}, input_normalization_modes={'observation.image': 'mean_std', 'observation.state': 'min_max'}, output_normalization_modes={'action': 'min_max'}, vision_backbone='resnet18', crop_shape=[84, 84], crop_is_random=True, pretrained_backbone_weights=None, use_group_norm=True, spatial_softmax_num_keypoints=32, use_separate_rgb_encoder_per_camera=False, down_dims=[512, 1024, 2048], kernel_size=5, n_groups=8, diffusion_step_embed_dim=128, use_film_scale_modulation=True, noise_scheduler_type='DDIM', num_train_timesteps=100, beta_schedule='squaredcos_cap_v2', beta_start=0.0001, beta_end=0.02, prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, num_inference_steps=100, do_mask_loss_for_padding=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0 reward=0.3549526479034709 terminated=False\n",
      "step=1 reward=0.3549526479034709 terminated=False\n",
      "step=2 reward=0.3549526479034709 terminated=False\n",
      "step=3 reward=0.3549526479034709 terminated=False\n",
      "step=4 reward=0.3549526479034709 terminated=False\n",
      "step=5 reward=0.3549526479034709 terminated=False\n",
      "step=6 reward=0.3549526479034709 terminated=False\n",
      "step=7 reward=0.3549526479034709 terminated=False\n",
      "step=8 reward=0.3549526479034709 terminated=False\n",
      "step=9 reward=0.3549526479034709 terminated=False\n",
      "step=10 reward=0.3549526479034709 terminated=False\n",
      "step=11 reward=0.3549526479034709 terminated=False\n",
      "step=12 reward=0.3549526479034709 terminated=False\n",
      "step=13 reward=0.3583105184393292 terminated=False\n",
      "step=14 reward=0.37652863787608654 terminated=False\n",
      "step=15 reward=0.39283125939387686 terminated=False\n",
      "step=16 reward=0.36670874447322566 terminated=False\n",
      "step=17 reward=0.3135768316292473 terminated=False\n",
      "step=18 reward=0.26680185903854986 terminated=False\n",
      "step=19 reward=0.22731800821590223 terminated=False\n",
      "step=20 reward=0.19817760238383214 terminated=False\n",
      "step=21 reward=0.17532835204008107 terminated=False\n",
      "step=22 reward=0.16264160332076694 terminated=False\n",
      "step=23 reward=0.15243372165637142 terminated=False\n",
      "step=24 reward=0.14337798247526753 terminated=False\n",
      "step=25 reward=0.14232172458870698 terminated=False\n",
      "step=26 reward=0.14794198007709417 terminated=False\n",
      "step=27 reward=0.15321453091366277 terminated=False\n",
      "step=28 reward=0.1642780778874096 terminated=False\n",
      "step=29 reward=0.1822502607680702 terminated=False\n",
      "step=30 reward=0.1972389905131004 terminated=False\n",
      "step=31 reward=0.20608917274723096 terminated=False\n",
      "step=32 reward=0.21663633041552732 terminated=False\n",
      "step=33 reward=0.23218910070903695 terminated=False\n",
      "step=34 reward=0.24536793825986042 terminated=False\n",
      "step=35 reward=0.24981957462777118 terminated=False\n",
      "step=36 reward=0.24333616238305547 terminated=False\n",
      "step=37 reward=0.22664825739360717 terminated=False\n",
      "step=38 reward=0.20403775032377963 terminated=False\n",
      "step=39 reward=0.18530785629585678 terminated=False\n",
      "step=40 reward=0.17236355535255057 terminated=False\n",
      "step=41 reward=0.15830809013828143 terminated=False\n",
      "step=42 reward=0.15642144034676775 terminated=False\n",
      "step=43 reward=0.15642144034676775 terminated=False\n",
      "step=44 reward=0.15642144034676775 terminated=False\n",
      "step=45 reward=0.15642144034676775 terminated=False\n",
      "step=46 reward=0.15642144034676775 terminated=False\n",
      "step=47 reward=0.15642144034676775 terminated=False\n",
      "step=48 reward=0.15642144034676775 terminated=False\n",
      "step=49 reward=0.15642144034676775 terminated=False\n",
      "step=50 reward=0.15642144034676775 terminated=False\n",
      "step=51 reward=0.15642144034676775 terminated=False\n",
      "step=52 reward=0.15642144034676775 terminated=False\n",
      "step=53 reward=0.15642144034676775 terminated=False\n",
      "step=54 reward=0.15642144034676775 terminated=False\n",
      "step=55 reward=0.15642144034676775 terminated=False\n",
      "step=56 reward=0.15642144034676775 terminated=False\n",
      "step=57 reward=0.15642144034676775 terminated=False\n",
      "step=58 reward=0.15533402122885534 terminated=False\n",
      "step=59 reward=0.15074791839671278 terminated=False\n",
      "step=60 reward=0.14515060535754506 terminated=False\n",
      "step=61 reward=0.138857575489329 terminated=False\n",
      "step=62 reward=0.13197992212710277 terminated=False\n",
      "step=63 reward=0.12503317840862468 terminated=False\n",
      "step=64 reward=0.11883325154564048 terminated=False\n",
      "step=65 reward=0.11449767525338278 terminated=False\n",
      "step=66 reward=0.11782347262320866 terminated=False\n",
      "step=67 reward=0.12448132408436531 terminated=False\n",
      "step=68 reward=0.13482668170134102 terminated=False\n",
      "step=69 reward=0.15077466752701896 terminated=False\n",
      "step=70 reward=0.17384694066570744 terminated=False\n",
      "step=71 reward=0.19811960786879873 terminated=False\n",
      "step=72 reward=0.22335762879159593 terminated=False\n",
      "step=73 reward=0.25807126628541843 terminated=False\n",
      "step=74 reward=0.3042717573938132 terminated=False\n",
      "step=75 reward=0.36450476902532586 terminated=False\n",
      "step=76 reward=0.4346024398115149 terminated=False\n",
      "step=77 reward=0.5091160895279662 terminated=False\n",
      "step=78 reward=0.5823261255682952 terminated=False\n",
      "step=79 reward=0.6423411934389766 terminated=False\n",
      "step=80 reward=0.6929557313206561 terminated=False\n",
      "step=81 reward=0.733424058886295 terminated=False\n",
      "step=82 reward=0.7634476413672301 terminated=False\n",
      "step=83 reward=0.7828086508036377 terminated=False\n",
      "step=84 reward=0.7946976125941516 terminated=False\n",
      "step=85 reward=0.7990914634442408 terminated=False\n",
      "step=86 reward=0.7991442872152072 terminated=False\n",
      "step=87 reward=0.796273725693843 terminated=False\n",
      "step=88 reward=0.7967806850763117 terminated=False\n",
      "step=89 reward=0.7967806850763117 terminated=False\n",
      "step=90 reward=0.7967806850763117 terminated=False\n",
      "step=91 reward=0.7967806850763117 terminated=False\n",
      "step=92 reward=0.7967806850763117 terminated=False\n",
      "step=93 reward=0.7967806850763117 terminated=False\n",
      "step=94 reward=0.7967806850763117 terminated=False\n",
      "step=95 reward=0.7967806850763117 terminated=False\n",
      "step=96 reward=0.7967806850763117 terminated=False\n",
      "step=97 reward=0.7967806850763117 terminated=False\n",
      "step=98 reward=0.7967806850763117 terminated=False\n",
      "step=99 reward=0.7967806850763117 terminated=False\n",
      "step=100 reward=0.7967806850763117 terminated=False\n",
      "step=101 reward=0.7967806850763117 terminated=False\n",
      "step=102 reward=0.7967806850763117 terminated=False\n",
      "step=103 reward=0.7967806850763117 terminated=False\n",
      "step=104 reward=0.7967806850763117 terminated=False\n",
      "step=105 reward=0.7967806850763117 terminated=False\n",
      "step=106 reward=0.7967806850763117 terminated=False\n",
      "step=107 reward=0.7967806850763117 terminated=False\n",
      "step=108 reward=0.7967806850763117 terminated=False\n",
      "step=109 reward=0.7967806850763117 terminated=False\n",
      "step=110 reward=0.7967806850763117 terminated=False\n",
      "step=111 reward=0.8145999869968125 terminated=False\n",
      "step=112 reward=0.8445886705709843 terminated=False\n",
      "step=113 reward=0.8678734591470229 terminated=False\n",
      "step=114 reward=0.8836216857070367 terminated=False\n",
      "step=115 reward=0.8909343764176485 terminated=False\n",
      "step=116 reward=0.8975197219172829 terminated=False\n",
      "step=117 reward=0.9059497274720703 terminated=False\n",
      "step=118 reward=0.9076858943844567 terminated=False\n",
      "step=119 reward=0.9076858943844567 terminated=False\n",
      "step=120 reward=0.9076858943844567 terminated=False\n",
      "step=121 reward=0.9076858943844567 terminated=False\n",
      "step=122 reward=0.9076858943844567 terminated=False\n",
      "step=123 reward=0.9076858943844567 terminated=False\n",
      "step=124 reward=0.9076858943844567 terminated=False\n",
      "step=125 reward=0.9076858943844567 terminated=False\n",
      "step=126 reward=0.9076858943844567 terminated=False\n",
      "step=127 reward=0.9076858943844567 terminated=False\n",
      "step=128 reward=0.9076858943844567 terminated=False\n",
      "step=129 reward=0.9076858943844567 terminated=False\n",
      "step=130 reward=0.9076858943844567 terminated=False\n",
      "step=131 reward=0.9076858943844567 terminated=False\n",
      "step=132 reward=0.9076858943844567 terminated=False\n",
      "step=133 reward=0.9076858943844567 terminated=False\n",
      "step=134 reward=0.9076858943844567 terminated=False\n",
      "step=135 reward=0.9353976773727815 terminated=False\n",
      "step=136 reward=0.9866345841595145 terminated=False\n",
      "step=137 reward=0.9818862954853307 terminated=False\n",
      "step=138 reward=0.9816470237038792 terminated=False\n",
      "step=139 reward=0.9816470237038792 terminated=False\n",
      "step=140 reward=0.9816470237038792 terminated=False\n",
      "step=141 reward=0.9816470237038792 terminated=False\n",
      "step=142 reward=0.9816470237038792 terminated=False\n",
      "step=143 reward=0.9816470237038792 terminated=False\n",
      "step=144 reward=0.9816470237038792 terminated=False\n",
      "step=145 reward=0.9816470237038792 terminated=False\n",
      "step=146 reward=0.9816470237038792 terminated=False\n",
      "step=147 reward=0.9816470237038792 terminated=False\n",
      "step=148 reward=0.9816470237038792 terminated=False\n",
      "step=149 reward=0.9816470237038792 terminated=False\n",
      "step=150 reward=0.975088187954328 terminated=False\n",
      "step=151 reward=0.946003868845796 terminated=False\n",
      "step=152 reward=0.9445717208996651 terminated=False\n",
      "step=153 reward=0.9445717208996651 terminated=False\n",
      "step=154 reward=0.9445717208996651 terminated=False\n",
      "step=155 reward=0.9445717208996651 terminated=False\n",
      "step=156 reward=0.9445717208996651 terminated=False\n",
      "step=157 reward=0.9445717208996651 terminated=False\n",
      "step=158 reward=0.9445717208996651 terminated=False\n",
      "step=159 reward=0.9445717208996651 terminated=False\n",
      "step=160 reward=0.9445717208996651 terminated=False\n",
      "step=161 reward=0.9445717208996651 terminated=False\n",
      "step=162 reward=0.9445717208996651 terminated=False\n",
      "step=163 reward=0.9445717208996651 terminated=False\n",
      "step=164 reward=0.9445717208996651 terminated=False\n",
      "step=165 reward=0.9445717208996651 terminated=False\n",
      "step=166 reward=0.9445717208996651 terminated=False\n",
      "step=167 reward=0.9445717208996651 terminated=False\n",
      "step=168 reward=0.9445717208996651 terminated=False\n",
      "step=169 reward=0.9445717208996651 terminated=False\n",
      "step=170 reward=0.9445717208996651 terminated=False\n",
      "step=171 reward=0.9445717208996651 terminated=False\n",
      "step=172 reward=0.9445717208996651 terminated=False\n",
      "step=173 reward=0.9445717208996651 terminated=False\n",
      "step=174 reward=0.9445717208996651 terminated=False\n",
      "step=175 reward=0.9445717208996651 terminated=False\n",
      "step=176 reward=0.9445717208996651 terminated=False\n",
      "step=177 reward=0.9445717208996651 terminated=False\n",
      "step=178 reward=0.9445717208996651 terminated=False\n",
      "step=179 reward=0.9445717208996651 terminated=False\n",
      "step=180 reward=0.9445717208996651 terminated=False\n",
      "step=181 reward=0.9445717208996651 terminated=False\n",
      "step=182 reward=0.9473258474795482 terminated=False\n",
      "step=183 reward=0.9489625193171604 terminated=False\n",
      "step=184 reward=0.9489625193171604 terminated=False\n",
      "step=185 reward=0.9489625193171604 terminated=False\n",
      "step=186 reward=0.9489625193171604 terminated=False\n",
      "step=187 reward=0.9489625193171604 terminated=False\n",
      "step=188 reward=0.9489625193171604 terminated=False\n",
      "step=189 reward=0.9489625193171604 terminated=False\n",
      "step=190 reward=0.9489625193171604 terminated=False\n",
      "step=191 reward=0.9489625193171604 terminated=False\n",
      "step=192 reward=0.9489625193171604 terminated=False\n",
      "step=193 reward=0.9489625193171604 terminated=False\n",
      "step=194 reward=0.9489625193171604 terminated=False\n",
      "step=195 reward=0.9489625193171604 terminated=False\n",
      "step=196 reward=0.9489625193171604 terminated=False\n",
      "step=197 reward=0.9489625193171604 terminated=False\n",
      "step=198 reward=0.9489625193171604 terminated=False\n",
      "step=199 reward=0.9489625193171604 terminated=False\n",
      "step=200 reward=0.9489625193171604 terminated=False\n",
      "step=201 reward=0.9489625193171604 terminated=False\n",
      "step=202 reward=0.9489625193171604 terminated=False\n",
      "step=203 reward=0.9489625193171604 terminated=False\n",
      "step=204 reward=0.9489625193171604 terminated=False\n",
      "step=205 reward=0.9489625193171604 terminated=False\n",
      "step=206 reward=0.9489625193171604 terminated=False\n",
      "step=207 reward=0.9489625193171604 terminated=False\n",
      "step=208 reward=0.9489625193171604 terminated=False\n",
      "step=209 reward=0.9489625193171604 terminated=False\n",
      "step=210 reward=0.9489625193171604 terminated=False\n",
      "step=211 reward=0.9489625193171604 terminated=False\n",
      "step=212 reward=0.9489625193171604 terminated=False\n",
      "step=213 reward=0.9489625193171604 terminated=False\n",
      "step=214 reward=0.9489625193171604 terminated=False\n",
      "step=215 reward=0.9489625193171604 terminated=False\n",
      "step=216 reward=0.9489625193171604 terminated=False\n",
      "step=217 reward=0.9489625193171604 terminated=False\n",
      "step=218 reward=0.9489625193171604 terminated=False\n",
      "step=219 reward=0.9489625193171604 terminated=False\n",
      "step=220 reward=0.9489625193171604 terminated=False\n",
      "step=221 reward=0.9489625193171604 terminated=False\n",
      "step=222 reward=0.9489625193171604 terminated=False\n",
      "step=223 reward=0.9489625193171604 terminated=False\n",
      "step=224 reward=0.9489625193171604 terminated=False\n",
      "step=225 reward=0.9489625193171604 terminated=False\n",
      "step=226 reward=0.9489625193171604 terminated=False\n",
      "step=227 reward=0.9489625193171604 terminated=False\n",
      "step=228 reward=0.9489625193171604 terminated=False\n",
      "step=229 reward=0.9489625193171604 terminated=False\n",
      "step=230 reward=0.9489625193171604 terminated=False\n",
      "step=231 reward=0.9489625193171604 terminated=False\n",
      "step=232 reward=0.9489625193171604 terminated=False\n",
      "step=233 reward=0.9489625193171604 terminated=False\n",
      "step=234 reward=0.9489625193171604 terminated=False\n",
      "step=235 reward=0.9489625193171604 terminated=False\n",
      "step=236 reward=0.9489625193171604 terminated=False\n",
      "step=237 reward=0.9489625193171604 terminated=False\n",
      "step=238 reward=0.9489625193171604 terminated=False\n",
      "step=239 reward=0.9489625193171604 terminated=False\n",
      "step=240 reward=0.9489625193171604 terminated=False\n",
      "step=241 reward=0.9489625193171604 terminated=False\n",
      "step=242 reward=0.9489625193171604 terminated=False\n",
      "step=243 reward=0.9489625193171604 terminated=False\n",
      "step=244 reward=0.9489625193171604 terminated=False\n",
      "step=245 reward=0.9489625193171604 terminated=False\n",
      "step=246 reward=0.9489625193171604 terminated=False\n",
      "step=247 reward=0.9489625193171604 terminated=False\n",
      "step=248 reward=0.9489625193171604 terminated=False\n",
      "step=249 reward=0.9489625193171604 terminated=False\n",
      "step=250 reward=0.9489625193171604 terminated=False\n",
      "step=251 reward=0.9489625193171604 terminated=False\n",
      "step=252 reward=0.9489625193171604 terminated=False\n",
      "step=253 reward=0.9489625193171604 terminated=False\n",
      "step=254 reward=0.9489625193171604 terminated=False\n",
      "step=255 reward=0.9489625193171604 terminated=False\n",
      "step=256 reward=0.9489625193171604 terminated=False\n",
      "step=257 reward=0.9489625193171604 terminated=False\n",
      "step=258 reward=0.9489625193171604 terminated=False\n",
      "step=259 reward=0.9489625193171604 terminated=False\n",
      "step=260 reward=0.9489625193171604 terminated=False\n",
      "step=261 reward=0.9489625193171604 terminated=False\n",
      "step=262 reward=0.9489625193171604 terminated=False\n",
      "step=263 reward=0.9489625193171604 terminated=False\n",
      "step=264 reward=0.9489625193171604 terminated=False\n",
      "step=265 reward=0.9489625193171604 terminated=False\n",
      "step=266 reward=0.9489625193171604 terminated=False\n",
      "step=267 reward=0.9489625193171604 terminated=False\n",
      "step=268 reward=0.9489625193171604 terminated=False\n",
      "step=269 reward=0.9489625193171604 terminated=False\n",
      "step=270 reward=0.9489625193171604 terminated=False\n",
      "step=271 reward=0.9489625193171604 terminated=False\n",
      "step=272 reward=0.9489625193171604 terminated=False\n",
      "step=273 reward=0.9489625193171604 terminated=False\n",
      "step=274 reward=0.9489625193171604 terminated=False\n",
      "step=275 reward=0.9489625193171604 terminated=False\n",
      "step=276 reward=0.9489625193171604 terminated=False\n",
      "step=277 reward=0.9489625193171604 terminated=False\n",
      "step=278 reward=0.9489625193171604 terminated=False\n",
      "step=279 reward=0.9489625193171604 terminated=False\n",
      "step=280 reward=0.9489625193171604 terminated=False\n",
      "step=281 reward=0.9489625193171604 terminated=False\n",
      "step=282 reward=0.9489625193171604 terminated=False\n",
      "step=283 reward=0.9489625193171604 terminated=False\n",
      "step=284 reward=0.9489625193171604 terminated=False\n",
      "step=285 reward=0.9489625193171604 terminated=False\n",
      "step=286 reward=0.9489625193171604 terminated=False\n",
      "step=287 reward=0.9489625193171604 terminated=False\n",
      "step=288 reward=0.9489625193171604 terminated=False\n",
      "step=289 reward=0.9489625193171604 terminated=False\n",
      "step=290 reward=0.9489625193171604 terminated=False\n",
      "step=291 reward=0.9489625193171604 terminated=False\n",
      "step=292 reward=0.9489625193171604 terminated=False\n",
      "step=293 reward=0.9489625193171604 terminated=False\n",
      "step=294 reward=0.9489625193171604 terminated=False\n",
      "step=295 reward=0.9489625193171604 terminated=False\n",
      "step=296 reward=0.9489625193171604 terminated=False\n",
      "step=297 reward=0.9489625193171604 terminated=False\n",
      "step=298 reward=0.9489625193171604 terminated=False\n",
      "step=299 reward=0.9489625193171604 terminated=False\n"
     ]
    }
   ],
   "source": [
    "# Reset the policy and environmens to prepare for rollout\n",
    "\n",
    "numpy_observation, info = env.reset(seed=1234)\n",
    "\n",
    "# Prepare to collect every rewards and all the frames of the episode,\n",
    "# from initial state to final state.\n",
    "rewards = []\n",
    "frames = []\n",
    "\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n",
    "\n",
    "step = 0\n",
    "done = False\n",
    "while not done:\n",
    "    # Prepare observation for the policy running in Pytorch\n",
    "    state = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    image = torch.from_numpy(numpy_observation[\"pixels\"])\n",
    "\n",
    "    # Convert to float32 with image from channel first in [0,255]\n",
    "    # to channel last in [0,1]\n",
    "    state = state.to(torch.float32)\n",
    "    image = image.to(torch.float32) / 255\n",
    "    image = image.permute(2, 0, 1)\n",
    "\n",
    "    # Send data tensors from CPU to GPU\n",
    "    state = state.to(device, non_blocking=True)\n",
    "    image = image.to(device, non_blocking=True)\n",
    "\n",
    "    # Add extra (empty) batch dimension, required to forward the policy\n",
    "    state = state.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Create the policy input dictionary\n",
    "    observation = {\n",
    "        \"observation.state\": state,\n",
    "        \"observation.image\": image,\n",
    "    }\n",
    "    \n",
    "    # Predict the next action with respect to the current observation\n",
    "    with torch.inference_mode():\n",
    "        action = policy.select_action(observation)\n",
    "\n",
    "    # Prepare the action for the environment\n",
    "    numpy_action = action.squeeze(0).to(\"cpu\").numpy()\n",
    "    # print(numpy_action)\n",
    "    # Step through the environment and receive a new observation\n",
    "    numpy_observation, reward, terminated, truncated, info = env.step(numpy_action)\n",
    "    print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "    # Keep track of all the rewards and frames\n",
    "    rewards.append(reward)\n",
    "    frames.append(env.render())\n",
    "\n",
    "    # The rollout is considered done when the success state is reach (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "    done = terminated | truncated | done\n",
    "    step += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (680, 680) to (688, 688) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x58e8140] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video of the evaluation is available in 'outputs/eval/example_pusht_diffusion/rollout.mp4'.\n"
     ]
    }
   ],
   "source": [
    "if terminated:\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"Failure!\")\n",
    "\n",
    "# Get the speed of environment (i.e. its number of frames per second).\n",
    "fps = env.metadata[\"render_fps\"]\n",
    "\n",
    "# Encode all frames into a mp4 video.\n",
    "video_path = output_directory / \"rollout.mp4\"\n",
    "imageio.mimsave(str(video_path), numpy.stack(frames), fps=fps)\n",
    "\n",
    "print(f\"Video of the evaluation is available in '{video_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
